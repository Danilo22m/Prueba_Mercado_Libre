# Conclusiones - Ejercicio 1: LLM vs Modelo Cl√°sico

## Resumen Ejecutivo

Este documento presenta las conclusiones del an√°lisis comparativo entre un modelo basado en LLM (Modelo A) y un modelo cl√°sico de Machine Learning (Modelo B - Isolation Forest) para la detecci√≥n de anomal√≠as en series temporales de precios.

**Fecha del An√°lisis**: 2026-01-12
**Autor**: Danilo Melo

---

## 1. Resultados de Evaluaci√≥n

### Modelo A - LLM (Groq API)

**Dataset**: 300 registros (muestra aleatoria del test set)

| M√©trica | Valor |
|---------|-------|
| **Precision** | 2.76% |
| **Recall** | 100% |
| **F1-Score** | 5.36% |
| **PR-AUC** | 0.461 |

**Matriz de Confusi√≥n**:
```
                Predicted
                Normal  Anomalo
Actual Normal     46      247
       Anomalo     0        7
```

**An√°lisis**:
- ‚úÖ **Recall perfecto (100%)**: Detecta TODAS las anomal√≠as reales
- ‚ùå **Precision muy baja (2.76%)**: Alta tasa de falsos positivos (247 FP)
- ‚ö†Ô∏è **Comportamiento conservador**: El modelo prefiere marcar como an√≥malo cuando tiene duda

### Modelo B - Isolation Forest

**Dataset**: 35,183 registros (test set completo)

| M√©trica | Valor |
|---------|-------|
| **Precision** | 18.93% |
| **Recall** | 21.41% |
| **F1-Score** | 20.09% |
| **PR-AUC** | 0.214 |

**Matriz de Confusi√≥n**:
```
                  Predicted
                  Normal  Anomalo
Actual Normal    33,983    574
       Anomalo      492    134
```

**An√°lisis**:
- ‚úÖ **Mejor precision (18.93% vs 2.76%)**: Menos falsos positivos
- ‚úÖ **Mejor F1-Score (20.09% vs 5.36%)**: Balance superior precision-recall
- ‚ùå **Recall moderado (21.41%)**: Pierde ~79% de anomal√≠as reales
- ‚úÖ **Escalable**: Procesa 35k registros vs 300 del LLM

---

## 2. A/B Testing Estad√≠stico

**M√©todo**: Bootstrap estratificado (1,000 iteraciones)
**Dataset Com√∫n**: 300 registros
**Nivel de Confianza**: 95% (Œ± = 0.05)

### Resultados del Bootstrap

| M√©trica | LLM (Media ¬± SD) | IF (Media ¬± SD) | Diferencia | p-value | Significativo |
|---------|------------------|-----------------|------------|---------|---------------|
| **Precision** | 2.76% ¬± 0.07% | 50.67% ¬± 27.49% | -47.91% | 0.178 | ‚ùå No |
| **Recall** | 100% ¬± 0% | 27.59% ¬± 16.20% | +72.41% | <0.001 | ‚úÖ **S√≠** |
| **F1-Score** | 5.37% ¬± 0.13% | 34.01% ¬± 17.78% | -28.64% | 0.178 | ‚ùå No |

### Intervalos de Confianza (95%)

- **Precision**: [-97.30%, +2.79%] - No significativo
- **Recall**: [+42.86%, +100%] - **Significativo** (LLM superior)
- **F1-Score**: [-61.38%, +5.43%] - No significativo

### Interpretaci√≥n

1. **Recall significativamente superior en LLM**: Con 100% de confianza estad√≠stica, el LLM tiene mejor recall
2. **Precision e F1 no significativos**: Alta variabilidad impide conclusiones definitivas
3. **Alta varianza en IF**: Desviaciones est√°ndar grandes (27.49% en precision) indican inestabilidad

---

## 3. An√°lisis Comparativo Detallado

### 3.1. Trade-offs Precision vs Recall

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 Precision vs Recall                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  LLM:    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100% Recall
‚îÇ          ‚ñà‚ñà 2.76% Precision                                 ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  IF:     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 21.41% Recall                           ‚îÇ
‚îÇ          ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 18.93% Precision                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**LLM**: Maximiza recall a costa de precision (estrategia "catch-all")
**IF**: Balance intermedio pero pierde muchas anomal√≠as reales

### 3.2. Costo Computacional

| Aspecto | LLM | Isolation Forest |
|---------|-----|------------------|
| **Tiempo de procesamiento** | ~20 min (600 registros) | ~5 seg (35k registros) |
| **Latencia por predicci√≥n** | ~2000 ms | <0.1 ms |
| **Escalabilidad** | ‚ùå Limitada (rate limits) | ‚úÖ Excelente |
| **Costo** | $0.00 (Groq gratis) | $0.00 (local) |
| **Infraestructura** | ‚òÅÔ∏è Requiere API externa | üíª Local |

### 3.3. Explicabilidad

| Aspecto | LLM | Isolation Forest |
|---------|-----|------------------|
| **Explicaciones** | ‚úÖ Razones en lenguaje natural | ‚ùå Solo anomaly score |
| **Confidence** | ‚úÖ Score de 0.0-1.0 | ‚úÖ Anomaly score |
| **Interpretabilidad** | ‚úÖ Alta (humanos entienden) | ‚ö†Ô∏è Media (t√©cnico) |

**Ejemplo de explicaci√≥n LLM**:
```json
{
  "label": "ANOMALO",
  "confidence": 0.95,
  "reason": "Precio 3.5x por encima de la media hist√≥rica"
}
```

---

## 4. Casos de Uso Recomendados

### ‚úÖ Cu√°ndo usar LLM (Modelo A)

1. **Recall cr√≠tico**: Cuando NO detectar una anomal√≠a es muy costoso
   - Ejemplo: Fraude financiero, alertas de seguridad

2. **Explicabilidad requerida**: Cuando necesitas justificar decisiones a humanos
   - Ejemplo: Auditor√≠as, compliance, customer support

3. **Baja frecuencia**: Pocos registros por d√≠a/hora
   - Ejemplo: Precios de productos premium

4. **Prototipado r√°pido**: Exploraci√≥n inicial sin entrenar modelos

### ‚úÖ Cu√°ndo usar Isolation Forest (Modelo B)

1. **Alto volumen**: Miles/millones de predicciones por d√≠a
   - Ejemplo: Streaming de precios en tiempo real

2. **Latencia cr√≠tica**: Respuestas en <1ms requeridas
   - Ejemplo: Trading algor√≠tmico, sistemas de recomendaci√≥n

3. **Offline**: Sin acceso a APIs externas
   - Ejemplo: Edge computing, sistemas on-premise

4. **Balance precision-recall**: F1-Score es m√©trica clave

---

## 5. Limitaciones del Estudio

### Modelo A (LLM)

1. **Muestra peque√±a**: Solo 300 registros (vs 35k del IF)
   - Sesgo de muestreo posible
   - Intervalos de confianza amplios

2. **Prompt engineering**: Resultados sensibles al prompt usado
   - Un prompt diferente podr√≠a cambiar precision/recall
   - No se hizo optimizaci√≥n de prompt

3. **Rate limits**: 30 req/min limita experimentaci√≥n
   - No se probaron m√∫ltiples configuraciones
   - No se hizo tuning de temperatura/top_p

### Modelo B (Isolation Forest)

1. **Contamination fijo**: 2% basado en proporci√≥n real
   - No se optimiz√≥ este hiperpar√°metro
   - Podr√≠a mejorarse con tuning

2. **Features limitadas**: Solo 10 features engineered
   - M√°s features podr√≠an mejorar rendimiento
   - No se probaron transformaciones no lineales

### A/B Testing

1. **Dataset com√∫n peque√±o**: Solo 300 registros
   - Poder estad√≠stico limitado
   - Alta variabilidad en IF

2. **Distribuci√≥n diferente**: LLM sobre muestra aleatoria vs IF sobre test completo
   - Comparaci√≥n no perfectamente justa

---

## 6. Recomendaciones

### Arquitectura H√≠brida (Recomendada)

Combinar ambos modelos para maximizar fortalezas:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   Sistema H√≠brido                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  1. Isolation Forest (Filtro r√°pido)                       ‚îÇ
‚îÇ     ‚Üì                                                       ‚îÇ
‚îÇ     Detecta anomal√≠as candidatas (alta recall)             ‚îÇ
‚îÇ     ‚Üì                                                       ‚îÇ
‚îÇ  2. LLM (Validaci√≥n selectiva)                            ‚îÇ
‚îÇ     ‚Üì                                                       ‚îÇ
‚îÇ     Valida solo anomal√≠as candidatas con explicaci√≥n       ‚îÇ
‚îÇ     ‚Üì                                                       ‚îÇ
‚îÇ  3. Output final con explicaci√≥n                          ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Ventajas**:
- ‚úÖ Velocidad de IF para filtrado inicial
- ‚úÖ Explicabilidad de LLM para casos importantes
- ‚úÖ Balance costo-beneficio √≥ptimo

### Mejoras Futuras

#### Modelo A (LLM)
1. **Optimizar prompt**: Experimentar con diferentes estructuras
2. **Few-shot learning**: Incluir ejemplos en el prompt
3. **Ensemble de LLMs**: Combinar m√∫ltiples modelos (Groq, OpenAI, Anthropic)
4. **Fine-tuning**: Entrenar modelo espec√≠fico en datos hist√≥ricos

#### Modelo B (Isolation Forest)
1. **Hyperparameter tuning**: GridSearch/RandomSearch para contamination
2. **Feature engineering avanzado**: M√°s features estad√≠sticas
3. **Ensemble**: Combinar con otros modelos (LOF, One-Class SVM)
4. **Deep learning**: Probar Autoencoders o LSTMs

#### A/B Testing
1. **Aumentar muestra**: 1,000+ registros para LLM
2. **Estratificaci√≥n**: Asegurar distribuci√≥n similar de anomal√≠as
3. **M√©tricas adicionales**: MCC, Cohen's Kappa, ROC-AUC

---

## 7. Conclusiones Finales

### Hallazgos Clave

1. **LLM tiene recall superior (100%)** pero precision muy baja (2.76%)
   - Estrategia "catch-all" detecta todas las anomal√≠as pero con muchos falsos positivos

2. **Isolation Forest tiene mejor balance** (F1: 20.09% vs 5.36%)
   - Mejor para producci√≥n por velocidad y escalabilidad

3. **Diferencia en recall es estad√≠sticamente significativa** (p < 0.001)
   - LLM es significativamente mejor para no perder anomal√≠as reales

4. **Precision e F1 no son estad√≠sticamente diferentes** (p = 0.178)
   - Alta variabilidad impide conclusiones definitivas

### Respuesta a la Pregunta de Investigaci√≥n

**¬øPuede un LLM reemplazar un modelo cl√°sico para detecci√≥n de anomal√≠as?**

**Respuesta**: **NO** para uso general, **S√ç** para casos espec√≠ficos.

**Razones**:
- ‚ùå **Costo computacional**: 400x m√°s lento (2000ms vs 0.1ms por predicci√≥n)
- ‚ùå **Escalabilidad**: Rate limits impiden alto volumen
- ‚ùå **Precision baja**: 97% de falsos positivos es inviable
- ‚úÖ **Recall perfecto**: √ötil cuando no detectar es cr√≠tico
- ‚úÖ **Explicabilidad**: Valor agregado en escenarios de compliance

### Recomendaci√≥n Final

**Para producci√≥n en e-commerce**: **Isolation Forest** con monitoreo humano

**Para casos cr√≠ticos con bajo volumen**: **Sistema H√≠brido** (IF + LLM)

**Para exploraci√≥n y prototipado**: **LLM** por rapidez de implementaci√≥n

---

## 8. Referencias

### Archivos de Resultados

- **M√©tricas completas**: `outputs/results/evaluacion_completa.json`
- **A/B Test**: `outputs/results/ab_test_results.json`
- **Comparaci√≥n**: `outputs/results/comparacion_modelos.csv`
- **Predicciones LLM**: `outputs/results/predicciones_llm.csv`
- **Predicciones IF**: `outputs/results/predicciones_isolation_forest.csv`

### Visualizaciones

- **Matrices de confusi√≥n**: `outputs/plots/confusion_matrices.png`
- **Curvas PR**: `outputs/plots/precision_recall_curves.png`
- **Series temporales**: `outputs/plots/series_temporales_comparacion_modelos.png`

### Configuraci√≥n

- **Config YAML**: `config/config.yaml`
- **Modelo A**: 600 registros, llama-3.3-70b-versatile, temperature=0.0
- **Modelo B**: contamination=0.02, n_estimators=100

---

**Documento generado**: 2026-01-12
**Proyecto**: Prueba T√©cnica Mercado Libre - Ejercicio 1
**Autor**: Danilo Melo
